{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"factoryName": {
			"type": "string",
			"metadata": "Data Factory Name",
			"defaultValue": "adfln2"
		}
	},
	"variables": {
		"factoryId": "[concat('Microsoft.DataFactory/factories/', parameters('factoryName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('factoryName'), '/CopyMultiTableJSONArray')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "ForEachTableInArray",
						"type": "ForEach",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@pipeline().parameters.cw_items",
								"type": "Expression"
							},
							"isSequential": true,
							"activities": [
								{
									"name": "CopyFromSQLDBtoBlob",
									"type": "Copy",
									"dependsOn": [],
									"policy": {
										"timeout": "7.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [
										{
											"name": "Source",
											"value": "@{item().source.tableName}"
										},
										{
											"name": "Destination",
											"value": "raw/@{item().destination.fileName}"
										}
									],
									"typeProperties": {
										"source": {
											"type": "SqlSource"
										},
										"sink": {
											"type": "BlobSink"
										},
										"enableStaging": false,
										"enableSkipIncompatibleRow": true,
										"dataIntegrationUnits": 0
									},
									"inputs": [
										{
											"referenceName": "SourceDataset",
											"type": "DatasetReference",
											"parameters": {}
										}
									],
									"outputs": [
										{
											"referenceName": "SinkDataset",
											"type": "DatasetReference",
											"parameters": {}
										}
									]
								}
							]
						}
					}
				],
				"parameters": {
					"cw_items": {
						"type": "Array",
						"defaultValue": [
							{
								"source": {
									"tableName": "[[dbo].[mktzips]"
								},
								"destination": {
									"fileName": "[dbo].[mktzips].txt"
								}
							},
							{
								"source": {
									"tableName": "[[dbo].[zcshapes]"
								},
								"destination": {
									"fileName": "[dbo].[zcshapes].txt"
								}
							}
						]
					}
				},
				"folder": {
					"name": "Copy Demos"
				},
				"annotations": []
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/ETL with Azure Databricks')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"description": "Run a simple ETL job using Azure Databricks, with a single pane of glass monitoring from ADF.\n\nIn the template, we check for source dataset availability. Once it is available we copy it into a blob storage for staging using a Copy activity. The same storage is accessed from Databricks clusters while processing the data (ETL). The output is stored in the same storage under 'output' folder. Various notebook properties are referenced as expressions using pipeline parameters, which lets you configure more generic and reusable pipelines. \n \nFor steps on setting up storage and databricks notebook refer https://aka.ms/databricks-instructions. ",
				"activities": [
					{
						"name": "Availability flag",
						"description": "Lookup (or Get Metadata) activity is used to get information about the source files if they are available for processing. \nIn this template, only when the '_success' flag/ file is available at source, would the downstream activities be triggered. ",
						"type": "Lookup",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "BlobSource",
								"recursive": true
							},
							"dataset": {
								"referenceName": "SourceAvailabilityBlobStore1",
								"type": "DatasetReference",
								"parameters": {}
							}
						}
					},
					{
						"name": "file-to-blob",
						"description": "Copy activity copies the actual files/ dataset to be processed by Databricks into a staging store. This storage should be accessible by the Azure Databricks cluster referenced in the next activity. ",
						"type": "Copy",
						"dependsOn": [
							{
								"activity": "Availability flag",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "BlobSource",
								"recursive": true
							},
							"sink": {
								"type": "BlobSink"
							},
							"enableStaging": false,
							"dataIntegrationUnits": 0
						},
						"inputs": [
							{
								"referenceName": "SourceFilesBlobStore1",
								"type": "DatasetReference",
								"parameters": {}
							}
						],
						"outputs": [
							{
								"referenceName": "DestinationFilesBlobStore1",
								"type": "DatasetReference",
								"parameters": {}
							}
						]
					},
					{
						"name": "ETL",
						"description": "Databricks Notebook activity does the processing of the data copied in the previous step (copy activity).  Please ensure you have added the databricks notebook (<a href='https://adflabstaging1.blob.core.windows.net/share/Transformations.html' target='_blank'>https://adflabstaging1.blob.core.windows.net/share/Transformations.html</a>) in the databricks work-space and referenced it in the notebook activity in ADF.",
						"type": "DatabricksNotebook",
						"dependsOn": [
							{
								"activity": "file-to-blob",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"notebookPath": "/Shared/Transformations",
							"baseParameters": {
								"input": {
									"value": "@pipeline().parameters.inputPath",
									"type": "Expression"
								},
								"output": {
									"value": "@pipeline().parameters.outputPath",
									"type": "Expression"
								},
								"filename": {
									"value": "@pipeline().parameters.fileName",
									"type": "Expression"
								},
								"pipelineRunId": {
									"value": "@pipeline().RunId",
									"type": "Expression"
								}
							}
						},
						"linkedServiceName": {
							"referenceName": "lgndatabricks",
							"type": "LinkedServiceReference"
						}
					}
				],
				"parameters": {
					"inputPath": {
						"type": "String",
						"defaultValue": "/staged_sink"
					},
					"outputPath": {
						"type": "String",
						"defaultValue": "/processed_sink"
					},
					"fileName": {
						"type": "String",
						"defaultValue": "Product.csv"
					}
				},
				"annotations": []
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/IncrementalCopyPipeline')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "LookupOldWaterMarkActivity",
						"type": "Lookup",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "SqlSource"
							},
							"dataset": {
								"referenceName": "WatermarkDataset",
								"type": "DatasetReference",
								"parameters": {}
							},
							"firstRowOnly": true
						}
					},
					{
						"name": "LookupNewWaterMarkActivity",
						"type": "Lookup",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "SqlSource",
								"sqlReaderQuery": "select MAX(LastModifytime) as NewWatermarkvalue from data_source_table"
							},
							"dataset": {
								"referenceName": "SourceDataset",
								"type": "DatasetReference",
								"parameters": {}
							}
						}
					},
					{
						"name": "IncrementalCopyActivity",
						"type": "Copy",
						"dependsOn": [
							{
								"activity": "LookupOldWaterMarkActivity",
								"dependencyConditions": [
									"Succeeded"
								]
							},
							{
								"activity": "LookupNewWaterMarkActivity",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "SqlSource",
								"sqlReaderQuery": {
									"value": "select * from data_source_table where LastModifytime > '@{activity('LookupOldWaterMarkActivity').output.firstRow.WatermarkValue}' and LastModifytime <= '@{activity('LookupNewWaterMarkActivity').output.firstRow.NewWatermarkvalue}'",
									"type": "Expression"
								}
							},
							"sink": {
								"type": "DelimitedTextSink",
								"storeSettings": {
									"type": "AzureBlobFSWriteSetting"
								},
								"formatSettings": {
									"type": "DelimitedTextWriteSetting",
									"quoteAllText": true,
									"fileExtension": ".csv"
								}
							},
							"enableStaging": false,
							"dataIntegrationUnits": 0
						},
						"inputs": [
							{
								"referenceName": "SourceDataset",
								"type": "DatasetReference",
								"parameters": {}
							}
						],
						"outputs": [
							{
								"referenceName": "SpatialSink",
								"type": "DatasetReference",
								"parameters": {}
							}
						]
					},
					{
						"name": "StoredProceduretoWriteWatermarkActivity",
						"type": "SqlServerStoredProcedure",
						"dependsOn": [
							{
								"activity": "IncrementalCopyActivity",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"storedProcedureName": "[[dbo].[sp_write_watermark]",
							"storedProcedureParameters": {
								"LastModifiedtime": {
									"value": {
										"value": "@{activity('LookupNewWaterMarkActivity').output.firstRow.NewWatermarkvalue}",
										"type": "Expression"
									},
									"type": "DateTime"
								},
								"TableName": {
									"value": {
										"value": "@{activity('LookupOldWaterMarkActivity').output.firstRow.TableName}",
										"type": "Expression"
									},
									"type": "String"
								}
							}
						},
						"linkedServiceName": {
							"referenceName": "AzureSqlDatabaseLinkedService",
							"type": "LinkedServiceReference"
						}
					}
				],
				"folder": {
					"name": "Copy Demos"
				},
				"annotations": []
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Currency Converter1')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"description": "Sample demo data flow to convert currencies",
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "CurrencyDatasetUSD1",
								"type": "DatasetReference"
							},
							"name": "USDCurrency",
							"script": "source(output(\n\t\tColumn_1 as string,\n\t\tColumn_2 as string,\n\t\tColumn_3 as string,\n\t\tColumn_4 as string\n\t),\n\tallowSchemaDrift: false,\n\tvalidateSchema: false) ~> USDCurrency",
							"typeProperties": {}
						},
						{
							"dataset": {
								"referenceName": "CurrencyDatasetCAD1",
								"type": "DatasetReference"
							},
							"name": "CADSource",
							"script": "source(output(\n\t\tPreviousConversionRate as double,\n\t\tCountry as string,\n\t\tDateTime1 as string,\n\t\tCurrentConversionRate as double\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false) ~> CADSource",
							"typeProperties": {}
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "USDOutput1",
								"type": "DatasetReference"
							},
							"name": "USDSink",
							"script": "ConditionalSplit1@USD sink(allowSchemaDrift: true,\n\tvalidateSchema: false) ~> USDSink"
						},
						{
							"dataset": {
								"referenceName": "CADOutput1",
								"type": "DatasetReference"
							},
							"name": "CADSink",
							"script": "ConditionalSplit1@CAD sink(allowSchemaDrift: true,\n\tvalidateSchema: false) ~> CADSink"
						}
					],
					"transformations": [
						{
							"name": "Union",
							"description": "The Union combines 2 streams together",
							"script": "USDCurrency, CADSource union(byName: true)~> Union"
						},
						{
							"name": "NewCurrencyColumn",
							"description": "Create a new calculated column from currency rate",
							"script": "Union derive(NewCurrencyRate = round(CurrentConversionRate*1.25)) ~> NewCurrencyColumn"
						},
						{
							"name": "ConditionalSplit1",
							"description": "Split the data on state to create 2 streams",
							"script": "NewCurrencyColumn split(Country == 'USD',\n\tCountry == 'CAD',\n\tdisjoint: false) ~> ConditionalSplit1@(USD, CAD)"
						}
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/MovieDemo1')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "movie_dataflow_source1",
								"type": "DatasetReference"
							},
							"name": "Movies",
							"script": "source(output(\n\t\tmovieId as string,\n\t\ttitle as string,\n\t\tgenres as string\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false) ~> Movies",
							"typeProperties": {}
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "movie_dataflow_sink1",
								"type": "DatasetReference"
							},
							"name": "Output",
							"script": "MoviesYear sink(allowSchemaDrift: true,\n\tvalidateSchema: false) ~> Output"
						}
					],
					"transformations": [
						{
							"name": "MoviesYear",
							"script": "Movies derive(year = toInteger(trim(right(title, 6), '()')),\n\t\ttitle = toString(left(title, length(title)-6))) ~> MoviesYear"
						}
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/SearchLog1')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "searchLog1",
								"type": "DatasetReference"
							},
							"name": "searchLog",
							"script": "source(output(\n\t\t{_col0_} as integer,\n\t\t{_col1_} as string,\n\t\t{_col2_} as string,\n\t\t{_col3_} as string,\n\t\t{_col4_} as integer,\n\t\t{_col5_} as string,\n\t\t{_col6_} as string\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false) ~> searchLog",
							"typeProperties": {}
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "AzureSqlDWTable11_New1",
								"type": "DatasetReference"
							},
							"name": "sinkIntoDW",
							"script": "DurationFilter sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tformat: 'table',\n\tstaged: false,\n\tdeletable:false,\n\tinsertable:true,\n\tupdateable:false,\n\tupsertable:false) ~> sinkIntoDW"
						}
					],
					"transformations": [
						{
							"name": "totalDurationByRegion",
							"script": "DateFilter aggregate(groupBy(region),\n\ttotalduration = sum(duration)) ~> totalDurationByRegion"
						},
						{
							"name": "RenameColumns",
							"script": "searchLog select(mapColumn(\n\t\tuserid = {_col0_},\n\t\tstart = {_col1_},\n\t\tregion = {_col2_},\n\t\tquery = {_col3_},\n\t\tduration = {_col4_},\n\t\turls = {_col5_},\n\t\tclickedurls = {_col6_}\n\t))~> RenameColumns"
						},
						{
							"name": "DateFilter",
							"script": "ConvertDate filter(newdate > toDate('2012-02-06','yyyy-MM-dd')) ~> DateFilter"
						},
						{
							"name": "ConvertDate",
							"script": "RenameColumns derive(newdate = toDate(left(start,instr(start,' ')-1),'MM/dd/yyyy')) ~> ConvertDate"
						},
						{
							"name": "DurationFilter",
							"script": "totalDurationByRegion filter(totalduration > 200) ~> DurationFilter"
						}
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/TaxiDemo1')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "taxi_trip_data_input1",
								"type": "DatasetReference"
							},
							"name": "TripData",
							"script": "source(output(\n\t\tmedallion as string,\n\t\thack_license as string,\n\t\tvendor_id as string,\n\t\trate_code as string,\n\t\tstore_and_fwd_flag as string,\n\t\tpickup_datetime as string,\n\t\tdropoff_datetime as string,\n\t\tpassenger_count as short,\n\t\ttrip_time_in_secs as long,\n\t\ttrip_distance as double,\n\t\tpickup_longitude as double,\n\t\tpickup_latitude as double,\n\t\tdropoff_longitude as double,\n\t\tdropoff_latitude as double\n\t),\n\tallowSchemaDrift: false,\n\tvalidateSchema: false) ~> TripData",
							"typeProperties": {}
						},
						{
							"dataset": {
								"referenceName": "taxi_trip_fare_input1",
								"type": "DatasetReference"
							},
							"name": "TripFare",
							"script": "source(output(\n\t\tmedallion as string,\n\t\t{ hack_license} as string,\n\t\t{ vendor_id} as string,\n\t\t{ pickup_datetime} as string,\n\t\t{ payment_type} as string,\n\t\t{ fare_amount} as double,\n\t\t{ surcharge} as double,\n\t\t{ mta_tax} as double,\n\t\t{ tip_amount} as double,\n\t\t{ tolls_amount} as double,\n\t\t{ total_amount} as double\n\t),\n\tallowSchemaDrift: false,\n\tvalidateSchema: false) ~> TripFare",
							"typeProperties": {}
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "TaxiDemoVendorStatsSink1",
								"type": "DatasetReference"
							},
							"name": "VendorStatsSink",
							"script": "AggregateVendorStats sink(allowSchemaDrift: true,\n\tvalidateSchema: false) ~> VendorStatsSink"
						},
						{
							"dataset": {
								"referenceName": "TaxiDemoDayStatsSink1",
								"type": "DatasetReference"
							},
							"name": "DayStatsSink",
							"script": "AggregateDayStats sink(allowSchemaDrift: true,\n\tvalidateSchema: false) ~> DayStatsSink"
						},
						{
							"dataset": {
								"referenceName": "TaxiDemoTotalByPaymentType1",
								"type": "DatasetReference"
							},
							"name": "TotalPaymentByPaymentType",
							"script": "AggregateByPaymentType sink(allowSchemaDrift: true,\n\tvalidateSchema: false) ~> TotalPaymentByPaymentType"
						}
					],
					"transformations": [
						{
							"name": "JoinMatchedData",
							"script": "TripData, TripFare join(hack_license == { hack_license}\n\t&& TripData@medallion == TripFare@medallion\n\t&& vendor_id == { vendor_id}\n\t&& pickup_datetime == { pickup_datetime},\n\tjoinType:'inner',\n\tbroadcast: 'none')~> JoinMatchedData"
						},
						{
							"name": "AggregateVendorStats",
							"script": "JoinMatchedData aggregate(groupBy(vendor_id),\n\tpassenger_count = round(sum(passenger_count), 2),\n\t\ttrip_time_in_secs = round(sum(trip_time_in_secs)/60, 2),\n\t\ttrip_distance = round(sum(trip_distance), 2),\n\t\tTotalTripFare = round(sum({ total_amount}), 2)) ~> AggregateVendorStats"
						},
						{
							"name": "AggregateDayStats",
							"script": "JoinMatchedData aggregate(groupBy(DayOfTheWeek = dayOfWeek(toDate(pickup_datetime,'yyyy-mm-dd hh:mm:ss'))),\n\ttrip_distance = round(avg(trip_distance), 2),\n\t\tpassenger_count = round(avg(passenger_count), 2),\n\t\ttrip_time_in_secs = round(avg(trip_time_in_secs)/60, 2),\n\t\taverage_fare = round(avg({ total_amount}), 2)) ~> AggregateDayStats"
						},
						{
							"name": "AggregateByPaymentType",
							"script": "TripFare aggregate(groupBy({ payment_type}),\n\teach(match(type=='double'), concat($$, '_total') = round(sum ($$)))) ~> AggregateByPaymentType"
						}
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dedupeProb21')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "names1001",
								"type": "DatasetReference"
							},
							"name": "sourceName",
							"script": "source(output(\n\t\t{Emp ID} as integer,\n\t\t{Name Prefix} as string,\n\t\t{First Name} as string,\n\t\t{Middle Initial} as string,\n\t\t{Last Name} as string,\n\t\tGender as string,\n\t\t{E Mail} as string,\n\t\t{Father's Name} as string,\n\t\t{Mother's Name} as string,\n\t\t{Mother's Maiden Name} as string,\n\t\t{Date of Birth} as date,\n\t\t{Time of Birth} as string,\n\t\t{Age in Yrs.} as double,\n\t\t{Weight in Kgs.} as integer,\n\t\t{Date of Joining} as date,\n\t\t{Quarter of Joining} as string,\n\t\t{Half of Joining} as string,\n\t\t{Year of Joining} as short,\n\t\t{Month of Joining} as short,\n\t\t{Month Name of Joining} as string,\n\t\t{Short Month} as string,\n\t\t{Day of Joining} as short,\n\t\t{DOW of Joining} as string,\n\t\t{Short DOW} as string,\n\t\t{Age in Company (Years)} as double,\n\t\tSalary as integer,\n\t\t{Last % Hike} as string,\n\t\tSSN as string,\n\t\t{Phone No. } as string,\n\t\t{Place Name} as string,\n\t\tCounty as string,\n\t\tCity as string,\n\t\tState as string,\n\t\tZip as integer,\n\t\tRegion as string,\n\t\t{User Name} as string,\n\t\tPassword as string\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false) ~> sourceName",
							"typeProperties": {}
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "dupefolder1",
								"type": "DatasetReference"
							},
							"name": "sinkDupes",
							"script": "CheckForDupes@Duplicates sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tpartitionBy('hash', 1),\n\tpartitionFileNames:['dupes.csv']) ~> sinkDupes"
						},
						{
							"dataset": {
								"referenceName": "dupefolder1",
								"type": "DatasetReference"
							},
							"name": "sinkNoDupes",
							"script": "CheckForDupes@NotDupe sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tpartitionBy('hash', 1),\n\tpartitionFileNames:['nodupes.csv']) ~> sinkNoDupes"
						}
					],
					"transformations": [
						{
							"name": "FuzzyMatch",
							"script": "MapNames derive(SoundexValue = soundex(fullname)) ~> FuzzyMatch"
						},
						{
							"name": "groupSoundex",
							"script": "Orig1 aggregate(groupBy(SoundexValue),\n\tsoundexmatch = sum(1)) ~> groupSoundex"
						},
						{
							"name": "Orig1",
							"script": "FuzzyMatch select(mapColumn(\n\t\tacctnum,\n\t\tfullname,\n\t\tphone,\n\t\tzip,\n\t\tSoundexValue\n\t))~> Orig1"
						},
						{
							"name": "soundexJoin",
							"script": "groupSoundex, soundexBranch join(groupSoundex@SoundexValue == soundexBranch@SoundexValue,\n\tjoinType:'inner',\n\tbroadcast: 'none')~> soundexJoin"
						},
						{
							"name": "soundexBranch",
							"script": "FuzzyMatch select(mapColumn(\n\t\tacctnum,\n\t\tfullname,\n\t\tphone,\n\t\tzip,\n\t\tSoundexValue\n\t))~> soundexBranch"
						},
						{
							"name": "groupPhone",
							"script": "soundexJoin aggregate(groupBy(phone,\n\t\tsoundexBranch@SoundexValue),\n\tphonematch = sum(1),\n\t\tacctnum_agg = last(acctnum)) ~> groupPhone"
						},
						{
							"name": "phoneBranch",
							"script": "soundexJoin select(mapColumn(\n\t\tsoundexmatch,\n\t\tacctnum,\n\t\tfullname,\n\t\tphone,\n\t\tzip,\n\t\tSoundexValue = soundexBranch@SoundexValue\n\t))~> phoneBranch"
						},
						{
							"name": "phoneJoin",
							"script": "groupPhone, phoneBranch join(acctnum_agg == acctnum,\n\tjoinType:'right',\n\tbroadcast: 'none')~> phoneJoin"
						},
						{
							"name": "groupZip",
							"script": "phoneJoin aggregate(groupBy(zip,\n\t\tphoneBranch@SoundexValue),\n\tzipcount = sum(1),\n\t\tacctnum_agg = last(acctnum_agg)) ~> groupZip"
						},
						{
							"name": "zipBranch",
							"script": "phoneJoin select(mapColumn(\n\t\tphonematch,\n\t\tsoundexmatch,\n\t\tacctnum,\n\t\tfullname,\n\t\tphone = phoneBranch@phone,\n\t\tzip,\n\t\tSoundexValue = phoneBranch@SoundexValue\n\t))~> zipBranch"
						},
						{
							"name": "zipJoin",
							"script": "groupZip, zipBranch join(acctnum_agg == acctnum,\n\tjoinType:'right',\n\tbroadcast: 'none')~> zipJoin"
						},
						{
							"name": "setConstants",
							"script": "zipJoin derive(soundexweight = 50,\n\t\tzipweight = 25,\n\t\tphoneweight = 25,\n\t\tsoundexbool = iif (soundexmatch > 1, 1, 0),\n\t\tzipbool = iif (zipcount > 1, 1, 0),\n\t\tphonebool = iif (phonematch > 1, 1, 0)) ~> setConstants"
						},
						{
							"name": "matchScore",
							"script": "setConstants derive(matchscore = (soundexbool * 50) + (zipbool * 25) + (phonebool * 25)) ~> matchScore"
						},
						{
							"name": "finalResult",
							"script": "matchScore select(mapColumn(\n\t\tphone,\n\t\tacctnum,\n\t\tfullname,\n\t\tzip = zipBranch@zip,\n\t\tmatchscore\n\t))~> finalResult"
						},
						{
							"name": "MapNames",
							"script": "CreateFullName select(mapColumn(\n\t\tphone = {Phone No. },\n\t\tzip = Zip,\n\t\tfullname,\n\t\tacctnum = {Emp ID}\n\t))~> MapNames"
						},
						{
							"name": "CreateFullName",
							"script": "sourceName derive(fullname = {First Name} + ' ' + {Last Name}) ~> CreateFullName"
						},
						{
							"name": "CheckForDupes",
							"script": "finalResult split(matchscore > 50,\n\tdisjoint: false) ~> CheckForDupes@(Duplicates, NotDupe)"
						}
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/CurrencyConverter')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Currency Converter1",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "Currency Converter1",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"USDCurrency": {},
									"CADSource": {},
									"USDSink": {},
									"CADSink": {}
								}
							},
							"staging": {}
						}
					}
				],
				"folder": {
					"name": "Data Flow Demos"
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/Currency Converter1')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/Dedupe Pipeline')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Deduplication Data Flow",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "dedupeProb21",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"sourceName": {},
									"sinkDupes": {},
									"sinkNoDupes": {}
								}
							},
							"staging": {}
						}
					}
				],
				"folder": {
					"name": "Data Flow Demos"
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/dedupeProb21')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/SearchLogAnalytics')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"description": "This is a sample that takes the U-SQL SearchLog analytics example and turns it into an ADF Data Flow: https://kromerbigdata.com/2019/03/03/u-sql-searchlog-aggregations-as-adf-data-flows/",
				"activities": [
					{
						"name": "SearchLog",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "SearchLog1",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"searchLog": {},
									"sinkIntoDW": {}
								}
							},
							"staging": {}
						}
					}
				],
				"folder": {
					"name": "Data Flow Demos"
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/SearchLog1')]"
			]
		}
	]
}